# 数据集参数
dataset_conf:
  dataset:
    # 过滤最短的音频长度
    min_duration: 0.4
    # 最长的音频长度，大于这个长度会裁剪掉
    max_duration: 3
    # 音频的采样率
    sample_rate: 16000
    # 是否对音频进行音量归一化
    use_dB_normalization: True
    # 对音频进行音量归一化的音量分贝值
    target_dB: -20
  dataLoader:
    # 训练的批量大小
    batch_size: 64
    # 是否丢弃最后一个样本
    drop_last: True
    # 读取数据的线程数量
    num_workers: 8
  # 评估的数据要特殊处理
  eval_conf:
    # 评估的批量大小
    batch_size: 8
    # 最长的音频长度
    max_duration: 20
  # 训练数据的数据列表路径
  train_list: 'dataset/train_list.txt'
  # 测试数据的数据列表路径
  test_list: 'dataset/test_list.txt'
  # 标签列表
  label_list_path: 'dataset/label_list.txt'

# 数据预处理参数
preprocess_conf:
  # 是否使用HF上的Wav2Vec2类似模型提取音频特征
  use_hf_model: False
  # 音频预处理方法，也可以叫特征提取方法
  # 当use_hf_model为False时，支持：MelSpectrogram、Spectrogram、MFCC、Fbank
  # 当use_hf_model为True时，指定的是HuggingFace的模型或者本地路径，比如facebook/w2v-bert-2.0或者./feature_models/w2v-bert-2.0
  feature_method: 'Fbank'
  # 当use_hf_model为False时，设置API参数，更参数查看对应API，不清楚的可以直接删除该部分，直接使用默认值。
  # 当use_hf_model为True时，可以设置参数use_gpu，指定是否使用GPU提取特征
  method_args:
    sample_frequency: 16000
    num_mel_bins: 80

model_conf:
# 所使用的模型，支持PANNS_CNN6、PANNS_CNN10、PANNS_CNN14
  model: 'PANNS_CNN10'
  # 模型参数
  model_args:
    # 分类大小，如果为null，自动通过标签列表获取
    num_class: null

optimizer_conf:
  # 优化方法
  optimizer: 'Adam'
  # 优化方法参数
  optimizer_args:
    lr: 0.001
    weight_decay: !!float 1e-5
  # 学习率衰减函数，支持Pytorch支持的和项目提供的WarmupCosineSchedulerLR
  scheduler: 'WarmupCosineSchedulerLR'
  # 学习率衰减函数参数
  scheduler_args:
    min_lr: !!float 1e-5
    max_lr: 0.001
    warmup_epoch: 5

train_conf:
  # 是否开启自动混合精度
  enable_amp: False
  # 是否使用Pytorch2.0的编译器
  use_compile: False
  # CrossEntropyLoss类的label_smoothing参数
  label_smoothing: 0.0
  # 训练的轮数
  max_epoch: 60
  log_interval: 10
